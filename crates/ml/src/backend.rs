// Copyright 2025 SYNTON-DB Team
//
// Licensed under the Apache License, Version 2.0 (the "License");

//! Embedding backend traits and types.

use async_trait::async_trait;
use serde::{Deserialize, Serialize};

use crate::error::MlError;

/// Embedding backend type.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize, Default)]
#[serde(rename_all = "lowercase")]
pub enum BackendType {
    /// Local model using Candle.
    #[default]
    Local,

    /// OpenAI API.
    OpenAi,

    /// Ollama local API.
    Ollama,
}

impl std::fmt::Display for BackendType {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::Local => write!(f, "local"),
            Self::OpenAi => write!(f, "openai"),
            Self::Ollama => write!(f, "ollama"),
        }
    }
}

impl std::str::FromStr for BackendType {
    type Err = String;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        match s.to_lowercase().as_str() {
            "local" => Ok(Self::Local),
            "openai" => Ok(Self::OpenAi),
            "ollama" => Ok(Self::Ollama),
            _ => Err(format!("Unknown backend type: {s}")),
        }
    }
}

/// Embedding backend trait.
///
/// All embedding backends must implement this trait to provide
/// a unified interface for generating embeddings.
#[async_trait]
pub trait EmbeddingBackend: Send + Sync {
    /// Generate an embedding for a single text.
    ///
    /// # Errors
    ///
    /// Returns an error if:
    /// - The input is empty
    /// - The input exceeds maximum length
    /// - The backend fails to generate the embedding
    async fn embed(&self, text: &str) -> Result<Vec<f32>, MlError>;

    /// Generate embeddings for multiple texts in batch.
    ///
    /// # Errors
    ///
    /// Returns an error if:
    /// - Any input is empty
    /// - Any input exceeds maximum length
    /// - The backend fails to generate embeddings
    async fn embed_batch(&self, texts: &[String]) -> Result<Vec<Vec<f32>>, MlError> {
        // Default implementation calls embed for each text
        let mut results = Vec::with_capacity(texts.len());
        for text in texts {
            results.push(self.embed(text).await?);
        }
        Ok(results)
    }

    /// Returns the dimension of the embeddings generated by this backend.
    fn dimension(&self) -> usize;

    /// Returns the type of this backend.
    fn backend_type(&self) -> BackendType;
}

/// Device type for local models.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize, Default)]
#[serde(rename_all = "lowercase")]
pub enum DeviceType {
    /// CPU device.
    #[default]
    Cpu,

    /// GPU (CUDA) device.
    Cuda,

    /// GPU (Metal/MPS) device - for Apple Silicon.
    Metal,

    /// GPU (ROCm) device - for AMD.
    Rocm,
}

impl std::fmt::Display for DeviceType {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::Cpu => write!(f, "cpu"),
            Self::Cuda => write!(f, "cuda"),
            Self::Metal => write!(f, "metal"),
            Self::Rocm => write!(f, "rocm"),
        }
    }
}

impl std::str::FromStr for DeviceType {
    type Err = String;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        match s.to_lowercase().as_str() {
            "cpu" => Ok(Self::Cpu),
            "cuda" => Ok(Self::Cuda),
            "metal" | "mps" => Ok(Self::Metal),
            "rocm" | "amd" => Ok(Self::Rocm),
            _ => Err(format!("Unknown device type: {s}")),
        }
    }
}

/// Compute statistics for embeddings.
#[derive(Debug, Clone, Default)]
pub struct EmbeddingStats {
    /// Total number of embeddings generated.
    pub total_embeddings: usize,

    /// Total tokens processed.
    pub total_tokens: usize,

    /// Average embedding generation time (in milliseconds).
    pub avg_time_ms: f64,

    /// Number of cache hits.
    pub cache_hits: usize,
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::str::FromStr;

    #[test]
    fn test_backend_type_from_str() {
        assert_eq!(BackendType::from_str("local").unwrap(), BackendType::Local);
        assert_eq!(BackendType::from_str("LOCAL").unwrap(), BackendType::Local);
        assert_eq!(BackendType::from_str("openai").unwrap(), BackendType::OpenAi);
        assert_eq!(BackendType::from_str("ollama").unwrap(), BackendType::Ollama);
        assert!(BackendType::from_str("unknown").is_err());
    }

    #[test]
    fn test_backend_type_display() {
        assert_eq!(BackendType::Local.to_string(), "local");
        assert_eq!(BackendType::OpenAi.to_string(), "openai");
        assert_eq!(BackendType::Ollama.to_string(), "ollama");
    }

    #[test]
    fn test_device_type_from_str() {
        assert_eq!(DeviceType::from_str("cpu").unwrap(), DeviceType::Cpu);
        assert_eq!(DeviceType::from_str("cuda").unwrap(), DeviceType::Cuda);
        assert_eq!(DeviceType::from_str("metal").unwrap(), DeviceType::Metal);
        assert_eq!(DeviceType::from_str("mps").unwrap(), DeviceType::Metal);
        assert!(DeviceType::from_str("unknown").is_err());
    }

    #[test]
    fn test_device_type_display() {
        assert_eq!(DeviceType::Cpu.to_string(), "cpu");
        assert_eq!(DeviceType::Cuda.to_string(), "cuda");
        assert_eq!(DeviceType::Metal.to_string(), "metal");
        assert_eq!(DeviceType::Rocm.to_string(), "rocm");
    }

    #[test]
    fn test_backend_type_serialization() {
        let backend = BackendType::Local;
        let json = serde_json::to_string(&backend).unwrap();
        assert_eq!(json, "\"local\"");

        let parsed: BackendType = serde_json::from_str(&json).unwrap();
        assert_eq!(parsed, BackendType::Local);
    }
}
